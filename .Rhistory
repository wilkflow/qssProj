api_key = Sys.getenv("GEMINI_API_KEY"),
model = "gemini-pro") {
if (nchar(api_key) < 1) {
api_key <- readline("Paste your API key here: ")
Sys.setenv(GEMINI_API_KEY = api_key)
}
model_query <- paste0(model, ":generateContent")
response <- POST(
url = paste0("https://generativelanguage.googleapis.com/v1beta/models/", model_query),
query = list(key = api_key),
content_type_json(),
encode = "json",
body = list(
contents = list(
parts = lapply(prompts, function(prompt) list(text = prompt))
),
generationConfig = list(
temperature = temperature,
maxOutputTokens = max_output_tokens
)
)
)
if (response$status_code > 200) {
stop(paste("Error - ", content(response)$error$message))
}
candidates <- content(response)$candidates
outputs <- lapply(candidates, function(candidate) unlist(lapply(candidate$content$parts, function(part) part$text)))
return(outputs)
}
# Read in your dataset
text_emotion <- read.csv("./text_emotion.csv")
# Create a "gemini" column
text_emotion$gemini <- NA
# Define batch size
batch_size <- 10
# Run the loop in batches
num_batches <- ceiling(nrow(text_emotion) / batch_size)
# Start timing
tic.tic()
# Function to interact with Google's Gemini API
gemini <- function(prompts,
temperature = 0.0,
max_output_tokens = 1024,
api_key = Sys.getenv("GEMINI_API_KEY"),
model = "gemini-pro") {
if (nchar(api_key) < 1) {
api_key <- readline("Paste your API key here: ")
Sys.setenv(GEMINI_API_KEY = api_key)
}
model_query <- paste0(model, ":generateContent")
response <- POST(
url = paste0("https://generativelanguage.googleapis.com/v1beta/models/", model_query),
query = list(key = api_key),
content_type_json(),
encode = "json",
body = list(
contents = list(
parts = lapply(prompts, function(prompt) list(text = prompt))
),
generationConfig = list(
temperature = temperature,
maxOutputTokens = max_output_tokens
)
)
)
if (response$status_code > 200) {
stop(paste("Error - ", content(response)$error$message))
}
candidates <- content(response)$candidates
outputs <- lapply(candidates, function(candidate) unlist(lapply(candidate$content$parts, function(part) part$text)))
return(outputs)
}
# Read in your dataset
text_emotion <- read.csv("./text_emotion.csv")
# Create a "gemini" column
text_emotion$gemini <- NA
# Define batch size
batch_size <- 10
# Run the loop in batches
num_batches <- ceiling(nrow(text_emotion) / batch_size)
# Start timing
tic()
# Function to interact with Google's Gemini API
gemini <- function(prompts,
temperature = 0.0,
max_output_tokens = 1024,
api_key = Sys.getenv("GEMINI_API_KEY"),
model = "gemini-pro") {
if (nchar(api_key) < 1) {
api_key <- readline("Paste your API key here: ")
Sys.setenv(GEMINI_API_KEY = api_key)
}
model_query <- paste0(model, ":generateContent")
response <- POST(
url = paste0("https://generativelanguage.googleapis.com/v1beta/models/", model_query),
query = list(key = api_key),
content_type_json(),
encode = "json",
body = list(
contents = list(
parts = lapply(prompts, function(prompt) list(text = prompt))
),
generationConfig = list(
temperature = temperature,
maxOutputTokens = max_output_tokens
)
)
)
if (response$status_code > 200) {
stop(paste("Error - ", content(response)$error$message))
}
candidates <- content(response)$candidates
outputs <- lapply(candidates, function(candidate) unlist(lapply(candidate$content$parts, function(part) part$text)))
return(outputs)
}
# Read in your dataset
text_emotion <- read.csv("./text_emotion.csv")
# Create a "gemini" column
text_emotion$gemini <- NA
# Define batch size
batch_size <- 10
# Run the loop in batches
num_batches <- ceiling(nrow(text_emotion) / batch_size)
# Start timing
Tic()
# Function to interact with Google's Gemini API
gemini <- function(prompts,
temperature = 0.0,
max_output_tokens = 1024,
api_key = Sys.getenv("GEMINI_API_KEY"),
model = "gemini-pro") {
if (nchar(api_key) < 1) {
api_key <- readline("Paste your API key here: ")
Sys.setenv(GEMINI_API_KEY = api_key)
}
model_query <- paste0(model, ":generateContent")
response <- POST(
url = paste0("https://generativelanguage.googleapis.com/v1beta/models/", model_query),
query = list(key = api_key),
content_type_json(),
encode = "json",
body = list(
contents = list(
parts = lapply(prompts, function(prompt) list(text = prompt))
),
generationConfig = list(
temperature = temperature,
maxOutputTokens = max_output_tokens
)
)
)
if (response$status_code > 200) {
stop(paste("Error - ", content(response)$error$message))
}
candidates <- content(response)$candidates
outputs <- lapply(candidates, function(candidate) unlist(lapply(candidate$content$parts, function(part) part$text)))
return(outputs)
}
# Read in your dataset
text_emotion <- read.csv("./text_emotion.csv")
# Create a "gemini" column
text_emotion$gemini <- NA
# Define batch size
batch_size <- 10
# Run the loop in batches
num_batches <- ceiling(nrow(text_emotion) / batch_size)
# Start timing
#tic()
for (i in 1:num_batches) {
start_idx <- (i - 1) * batch_size + 1
end_idx <- min(i * batch_size, nrow(text_emotion))
batch_prompts <- text_emotion[start_idx:end_idx, "content"]
batch_results <- gemini(batch_prompts)
for (j in seq_along(batch_results)) {
question <- "Which sentiment best describes this text? Answer only with a number: 1 if anger, 2 if boredom, 3 if empty, 4 if enthusiasm, 5 if fun, 6 if happiness, 7 if hate, 8 if love, 9 if neutral, 10 if relief, 11 if sadness, 12 if surprise, 13 if worry. Here is the text:"
text <- batch_prompts[j]
concat <- paste(question, text)
result <- gemini(concat)
while (length(result) == 0) {
result <- gemini(concat)
}
text_emotion$gemini[start_idx + j - 1] <- result
}
cat("Processed batch", i, "of", num_batches, "\n")
}
# Function to interact with Google's Gemini API
library(httr)
gemini <- function(prompts,
temperature = 0.0,
max_output_tokens = 1024,
api_key = Sys.getenv("GEMINI_API_KEY"),
model = "gemini-pro") {
if (nchar(api_key) < 1) {
api_key <- readline("Paste your API key here: ")
Sys.setenv(GEMINI_API_KEY = api_key)
}
model_query <- paste0(model, ":generateContent")
response <- POST(
url = paste0("https://generativelanguage.googleapis.com/v1beta/models/", model_query),
query = list(key = api_key),
content_type_json(),
encode = "json",
body = list(
contents = list(
parts = lapply(prompts, function(prompt) list(text = prompt))
),
generationConfig = list(
temperature = temperature,
maxOutputTokens = max_output_tokens
)
)
)
if (response$status_code > 200) {
stop(paste("Error - ", content(response)$error$message))
}
candidates <- content(response)$candidates
outputs <- lapply(candidates, function(candidate) unlist(lapply(candidate$content$parts, function(part) part$text)))
return(outputs)
}
# Read in your dataset
text_emotion <- read.csv("./text_emotion.csv")
# Create a "gemini" column
text_emotion$gemini <- NA
# Define batch size
batch_size <- 10
# Run the loop in batches
num_batches <- ceiling(nrow(text_emotion) / batch_size)
# Start timing
#tic()
for (i in 1:num_batches) {
start_idx <- (i - 1) * batch_size + 1
end_idx <- min(i * batch_size, nrow(text_emotion))
batch_prompts <- text_emotion[start_idx:end_idx, "content"]
batch_results <- gemini(batch_prompts)
for (j in seq_along(batch_results)) {
question <- "Which sentiment best describes this text? Answer only with a number: 1 if anger, 2 if boredom, 3 if empty, 4 if enthusiasm, 5 if fun, 6 if happiness, 7 if hate, 8 if love, 9 if neutral, 10 if relief, 11 if sadness, 12 if surprise, 13 if worry. Here is the text:"
text <- batch_prompts[j]
concat <- paste(question, text)
result <- gemini(concat)
while (length(result) == 0) {
result <- gemini(concat)
}
text_emotion$gemini[start_idx + j - 1] <- result
}
cat("Processed batch", i, "of", num_batches, "\n")
}
# Function to interact with Google's Gemini API
library(httr)
gemini <- function(prompts,
temperature = 0.0,
max_output_tokens = 1024,
api_key = Sys.getenv("GEMINI_API_KEY"),
model = "gemini-pro") {
if (nchar(api_key) < 1) {
api_key <- readline("AIzaSyBO49GFLp1WYkqtzHfCWJs1r1VuGkRa864")
Sys.setenv(GEMINI_API_KEY = api_key)
}
model_query <- paste0(model, ":generateContent")
response <- POST(
url = paste0("https://generativelanguage.googleapis.com/v1beta/models/", model_query),
query = list(key = api_key),
content_type_json(),
encode = "json",
body = list(
contents = list(
parts = lapply(prompts, function(prompt) list(text = prompt))
),
generationConfig = list(
temperature = temperature,
maxOutputTokens = max_output_tokens
)
)
)
if (response$status_code > 200) {
stop(paste("Error - ", content(response)$error$message))
}
candidates <- content(response)$candidates
outputs <- lapply(candidates, function(candidate) unlist(lapply(candidate$content$parts, function(part) part$text)))
return(outputs)
}
# Read in your dataset
text_emotion <- read.csv("./text_emotion.csv")
# Create a "gemini" column
text_emotion$gemini <- NA
# Define batch size
batch_size <- 10
# Run the loop in batches
num_batches <- ceiling(nrow(text_emotion) / batch_size)
# Start timing
#tic()
for (i in 1:num_batches) {
start_idx <- (i - 1) * batch_size + 1
end_idx <- min(i * batch_size, nrow(text_emotion))
batch_prompts <- text_emotion[start_idx:end_idx, "content"]
batch_results <- gemini(batch_prompts)
for (j in seq_along(batch_results)) {
question <- "Which sentiment best describes this text? Answer only with a number: 1 if anger, 2 if boredom, 3 if empty, 4 if enthusiasm, 5 if fun, 6 if happiness, 7 if hate, 8 if love, 9 if neutral, 10 if relief, 11 if sadness, 12 if surprise, 13 if worry. Here is the text:"
text <- batch_prompts[j]
concat <- paste(question, text)
result <- gemini(concat)
while (length(result) == 0) {
result <- gemini(concat)
}
text_emotion$gemini[start_idx + j - 1] <- result
}
cat("Processed batch", i, "of", num_batches, "\n")
}
# Function to interact with Google's Gemini API
library(httr)
gemini <- function(prompts,
temperature = 0.0,
max_output_tokens = 1024,
api_key = Sys.getenv("GEMINI_API_KEY"),
model = "gemini-pro") {
if (nchar(api_key) < 1) {
api_key <- readline("AIzaSyBO49GFLp1WYkqtzHfCWJs1r1VuGkRa864")
Sys.setenv(GEMINI_API_KEY = "AIzaSyBO49GFLp1WYkqtzHfCWJs1r1VuGkRa864")
}
model_query <- paste0(model, ":generateContent")
response <- POST(
url = paste0("https://generativelanguage.googleapis.com/v1beta/models/", model_query),
query = list(key = api_key),
content_type_json(),
encode = "json",
body = list(
contents = list(
parts = lapply(prompts, function(prompt) list(text = prompt))
),
generationConfig = list(
temperature = temperature,
maxOutputTokens = max_output_tokens
)
)
)
if (response$status_code > 200) {
stop(paste("Error - ", content(response)$error$message))
}
candidates <- content(response)$candidates
outputs <- lapply(candidates, function(candidate) unlist(lapply(candidate$content$parts, function(part) part$text)))
return(outputs)
}
# Read in your dataset
text_emotion <- read.csv("./text_emotion.csv")
# Create a "gemini" column
text_emotion$gemini <- NA
# Define batch size
batch_size <- 10
# Run the loop in batches
num_batches <- ceiling(nrow(text_emotion) / batch_size)
# Start timing
#tic()
for (i in 1:num_batches) {
start_idx <- (i - 1) * batch_size + 1
end_idx <- min(i * batch_size, nrow(text_emotion))
batch_prompts <- text_emotion[start_idx:end_idx, "content"]
batch_results <- gemini(batch_prompts)
for (j in seq_along(batch_results)) {
question <- "Which sentiment best describes this text? Answer only with a number: 1 if anger, 2 if boredom, 3 if empty, 4 if enthusiasm, 5 if fun, 6 if happiness, 7 if hate, 8 if love, 9 if neutral, 10 if relief, 11 if sadness, 12 if surprise, 13 if worry. Here is the text:"
text <- batch_prompts[j]
concat <- paste(question, text)
result <- gemini(concat)
while (length(result) == 0) {
result <- gemini(concat)
}
text_emotion$gemini[start_idx + j - 1] <- result
}
cat("Processed batch", i, "of", num_batches, "\n")
}
# Function to interact with Google's Gemini API
library(httr)
gemini <- function(prompts,
temperature = 0.0,
max_output_tokens = 1024,
api_key = Sys.getenv("GEMINI_API_KEY"),
model = "gemini-pro") {
if (nchar(api_key) < 1) {
api_key <- "AIzaSyBO49GFLp1WYkqtzHfCWJs1r1VuGkRa864"
Sys.setenv(GEMINI_API_KEY = api_key)
}
model_query <- paste0(model, ":generateContent")
response <- POST(
url = paste0("https://generativelanguage.googleapis.com/v1beta/models/", model_query),
query = list(key = api_key),
content_type_json(),
encode = "json",
body = list(
contents = list(
parts = lapply(prompts, function(prompt) list(text = prompt))
),
generationConfig = list(
temperature = temperature,
maxOutputTokens = max_output_tokens
)
)
)
if (response$status_code > 200) {
stop(paste("Error - ", content(response)$error$message))
}
candidates <- content(response)$candidates
outputs <- lapply(candidates, function(candidate) unlist(lapply(candidate$content$parts, function(part) part$text)))
return(outputs)
}
# Read in your dataset
text_emotion <- read.csv("./text_emotion.csv")
# Create a "gemini" column
text_emotion$gemini <- NA
# Define batch size
batch_size <- 10
# Run the loop in batches
num_batches <- ceiling(nrow(text_emotion) / batch_size)
# Start timing
#tic()
for (i in 1:num_batches) {
start_idx <- (i - 1) * batch_size + 1
end_idx <- min(i * batch_size, nrow(text_emotion))
batch_prompts <- text_emotion[start_idx:end_idx, "content"]
batch_results <- gemini(batch_prompts)
for (j in seq_along(batch_results)) {
question <- "Which sentiment best describes this text? Answer only with a number: 1 if anger, 2 if boredom, 3 if empty, 4 if enthusiasm, 5 if fun, 6 if happiness, 7 if hate, 8 if love, 9 if neutral, 10 if relief, 11 if sadness, 12 if surprise, 13 if worry. Here is the text:"
text <- batch_prompts[j]
concat <- paste(question, text)
result <- gemini(concat)
while (length(result) == 0) {
result <- gemini(concat)
}
text_emotion$gemini[start_idx + j - 1] <- result
}
cat("Processed batch", i, "of", num_batches, "\n")
}
### Install Required Packages
library(httr)
library(tidyverse)
#########################
##### GPT prompting #####
#########################
# put your API key in the quotes below:
my_API <- "sk-proj-lyUbvpyCJVlM3H0szviDT3BlbkFJvXhvorQbAgjtdxXtUmgD"
#The "hey_chatGPT function will help you access the API and prompt GPT
hey_chatGPT <- function(answer_my_question) {
chat_GPT_answer <- POST(
url = "https://api.openai.com/v1/chat/completions",
add_headers(Authorization = paste("Bearer", my_API)),
content_type_json(),
encode = "json",
body = list(
model = "gpt-3.5-turbo-0301",
temperature = 0,
messages = list(
list(
role = "user",
content = answer_my_question
)
)
)
)
str_trim(content(chat_GPT_answer)$choices[[1]]$message$content)
}
# Read in your dataset
data <- read_csv("./text_emotion.csv")
data[1,1]
data[2,1]
data[2,1]
data[1,2]
data[1,3]
data[1,5]
data[1,4]
### Install Required Packages
library(httr)
library(tidyverse)
#########################
##### GPT prompting #####
#########################
# put your API key in the quotes below:
my_API <- "sk-proj-lyUbvpyCJVlM3H0szviDT3BlbkFJvXhvorQbAgjtdxXtUmgD"
#The "hey_chatGPT function will help you access the API and prompt GPT
hey_chatGPT <- function(answer_my_question) {
chat_GPT_answer <- POST(
url = "https://api.openai.com/v1/chat/completions",
add_headers(Authorization = paste("Bearer", my_API)),
content_type_json(),
encode = "json",
body = list(
model = "gpt-3.5-turbo-0301",
temperature = 0,
messages = list(
list(
role = "user",
content = answer_my_question
)
)
)
)
str_trim(content(chat_GPT_answer)$choices[[1]]$message$content)
}
# Read in your dataset
data <- read_csv("./text_emotion.csv")
# Create a "gpt" column
data$gpt <- NA
# Run a loop over your dataset and prompt ChatGPT - an example prompt for sentiment is given
for (i in 1:nrow(data)) {
print(i)
question <- "Is the sentiment of this text positive, neutral, or negative? Answer only with a number: 1 if positive, 2 if neutral, and 3 if negative. Here is the text:"
text <- data[i,4]
concat <- paste(question, text)
result <- hey_chatGPT(concat)
while(length(result) == 0){
result <- hey_chatGPT(concat)
print(result)
}
print(result)
data$gpt[i] <- result
}
